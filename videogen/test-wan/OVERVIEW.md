# Wan2.1 Video Server - Project Overview

## ğŸ“‹ Project Summary

A production-ready, high-performance video generation server built in Go that serves the LTX-Video (Wan2.1) model from Hugging Face. The application supports text-to-video, image-to-video, and video-to-video generation with GPU acceleration.

## ğŸ—ï¸ Architecture

### Two-Tier Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Client Applications              â”‚
â”‚     (Browser, Mobile, API Clients)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTP/REST
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Go Server (Port 8080)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  â€¢ HTTP API (Gin Framework)       â”‚  â”‚
â”‚  â”‚  â€¢ Request Validation             â”‚  â”‚
â”‚  â”‚  â€¢ File Upload Handling           â”‚  â”‚
â”‚  â”‚  â€¢ Job Queue Management           â”‚  â”‚
â”‚  â”‚  â€¢ Rate Limiting                  â”‚  â”‚
â”‚  â”‚  â€¢ Logging & Monitoring           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTP
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Python Backend (Port 5000)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  â€¢ PyTorch Model Loading          â”‚  â”‚
â”‚  â”‚  â€¢ GPU/CUDA Management            â”‚  â”‚
â”‚  â”‚  â€¢ Diffusers Pipeline             â”‚  â”‚
â”‚  â”‚  â€¢ Video Generation               â”‚  â”‚
â”‚  â”‚  â€¢ Frame Processing               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  NVIDIA GPU â”‚
         â”‚   (CUDA)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
wan2-video-server/
â”œâ”€â”€ cmd/                           # CLI commands
â”‚   â”œâ”€â”€ root.go                   # Main server command
â”‚   â””â”€â”€ download.go               # Model download command
â”‚
â”œâ”€â”€ pkg/                          # Go packages
â”‚   â”œâ”€â”€ config/                   # Configuration management
â”‚   â”‚   â””â”€â”€ config.go            # Config loader with viper
â”‚   â”œâ”€â”€ server/                   # HTTP server
â”‚   â”‚   â””â”€â”€ server.go            # Gin server setup
â”‚   â”œâ”€â”€ handlers/                 # HTTP request handlers
â”‚   â”‚   â”œâ”€â”€ health.go            # Health checks
â”‚   â”‚   â”œâ”€â”€ video.go             # Video generation endpoints
â”‚   â”‚   â”œâ”€â”€ model.go             # Model info
â”‚   â”‚   â””â”€â”€ model_management.go  # Model operations
â”‚   â”œâ”€â”€ middleware/               # HTTP middleware
â”‚   â”‚   â””â”€â”€ middleware.go        # CORS, logging, rate limiting
â”‚   â”œâ”€â”€ model/                    # Model engines
â”‚   â”‚   â”œâ”€â”€ engine.go            # Engine interface
â”‚   â”‚   â”œâ”€â”€ python_engine.go     # Python backend client
â”‚   â”‚   â”œâ”€â”€ local_engine.go      # Local inference (future)
â”‚   â”‚   â””â”€â”€ huggingface.go       # HF model downloader
â”‚   â”œâ”€â”€ types/                    # Type definitions
â”‚   â”‚   â””â”€â”€ types.go             # Request/response structs
â”‚   â”œâ”€â”€ logger/                   # Logging
â”‚   â”‚   â””â”€â”€ logger.go            # Logrus setup
â”‚   â””â”€â”€ utils/                    # Utilities
â”‚       â””â”€â”€ utils.go             # Helper functions
â”‚
â”œâ”€â”€ python_backend/               # Python inference server
â”‚   â”œâ”€â”€ server.py                # Flask API server
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â””â”€â”€ setup.sh                 # Setup script
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ API.md                   # API reference
â”‚   â”œâ”€â”€ CONFIGURATION.md         # Config guide
â”‚   â”œâ”€â”€ TESTING.md               # Testing guide
â”‚   â””â”€â”€ DEPLOYMENT.md            # Deployment guide
â”‚
â”œâ”€â”€ examples/                     # Example requests
â”‚   â”œâ”€â”€ api_examples.sh          # Shell script examples
â”‚   â””â”€â”€ postman_collection.json  # Postman collection
â”‚
â”œâ”€â”€ main.go                       # Application entry point
â”œâ”€â”€ go.mod                        # Go dependencies
â”œâ”€â”€ .env.example                  # Example configuration
â”œâ”€â”€ Dockerfile                    # Docker image definition
â”œâ”€â”€ docker-compose.yml            # Docker Compose config
â”œâ”€â”€ Makefile                      # Build automation
â”œâ”€â”€ setup.sh                      # Quick setup script
â”œâ”€â”€ README.md                     # Main documentation
â”œâ”€â”€ QUICKSTART.md                 # Quick start guide
â””â”€â”€ LICENSE                       # MIT license
```

## ğŸ¯ Key Features

### Video Generation Capabilities
- âœ… **Text-to-Video**: Generate videos from text descriptions
- âœ… **Image-to-Video**: Animate static images
- âœ… **Video-to-Video**: Transform existing videos

### Technical Features
- âœ… **GPU Acceleration**: CUDA support for faster inference
- âœ… **Async Processing**: Non-blocking job queue
- âœ… **Rate Limiting**: Prevent resource exhaustion
- âœ… **Model Caching**: Efficient model storage
- âœ… **File Management**: Upload and output handling
- âœ… **Health Monitoring**: Ready for production monitoring
- âœ… **CORS Support**: Cross-origin requests enabled
- âœ… **Structured Logging**: JSON logs for easy parsing

### Model Features
- ğŸ”§ Adjustable frame count (up to 128 frames)
- ğŸ”§ Configurable resolution (256x256 to 1024x1024+)
- ğŸ”§ Custom FPS settings
- ğŸ”§ Seed support for reproducibility
- ğŸ”§ Guidance scale tuning
- ğŸ”§ Inference step control
- ğŸ”§ Negative prompt support

## ğŸ”Œ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check |
| `/api/v1/model/info` | GET | Model information |
| `/api/v1/generate/text-to-video` | POST | Text-to-video generation |
| `/api/v1/generate/image-to-video` | POST | Image-to-video generation |
| `/api/v1/generate/video-to-video` | POST | Video-to-video generation |
| `/api/v1/job/:id` | GET | Job status |
| `/api/v1/models` | GET | List models |
| `/api/v1/models/download` | POST | Download model |
| `/outputs/*` | GET | Static file serving |

## ğŸ› ï¸ Technology Stack

### Backend (Go)
- **Web Framework**: Gin v1.9.1
- **Configuration**: Viper v1.18.2
- **CLI**: Cobra v1.8.0
- **Logging**: Logrus v1.9.3
- **Environment**: godotenv v1.5.1

### AI Backend (Python)
- **Web Framework**: Flask 3.0.0
- **ML Framework**: PyTorch 2.0+
- **Model Pipeline**: Diffusers 0.25+
- **Transformers**: Transformers 4.35+
- **Acceleration**: Accelerate 0.25+
- **Optimization**: xformers 0.0.22 (optional)

### Infrastructure
- **Containerization**: Docker, Docker Compose
- **GPU**: NVIDIA CUDA 11.8+
- **Reverse Proxy**: Nginx (optional)
- **Monitoring**: Prometheus, Grafana (optional)

## ğŸ“Š Performance Characteristics

### Generation Times (Approximate)

| Configuration | Resolution | Frames | GPU (T4) | GPU (A100) |
|--------------|------------|--------|----------|------------|
| Fast | 256x256 | 16 | ~10s | ~3s |
| Balanced | 512x512 | 64 | ~45s | ~15s |
| High Quality | 768x768 | 128 | ~120s | ~40s |

### Resource Requirements

| Scenario | GPU Memory | RAM | Concurrent Jobs |
|----------|------------|-----|-----------------|
| Minimal | 8GB | 16GB | 1 |
| Recommended | 16GB | 32GB | 2-3 |
| High Load | 24GB+ | 64GB | 4+ |

## ğŸš€ Quick Start Commands

```bash
# Setup
./setup.sh

# Download model
./wan2-video-server download

# Start services
# Terminal 1:
cd python_backend && source venv/bin/activate && python server.py

# Terminal 2:
./wan2-video-server

# Test
curl http://localhost:8080/health

# Generate video
curl -X POST http://localhost:8080/api/v1/generate/text-to-video \
  -H "Content-Type: application/json" \
  -d '{"prompt": "A cat playing", "num_frames": 32}'
```

## ğŸ” Security Considerations

- âœ… Input validation on all endpoints
- âœ… File size limits (100MB default)
- âœ… Rate limiting (2 concurrent requests default)
- âœ… Request timeouts (300s default)
- âš ï¸ No authentication (add in production)
- âš ï¸ No HTTPS (use reverse proxy)
- âš ï¸ No API keys (implement as needed)

## ğŸ“ˆ Scalability

### Horizontal Scaling
- Deploy multiple instances behind load balancer
- Use shared storage for models and outputs
- Implement Redis for distributed job queue

### Vertical Scaling
- Add more GPUs to single instance
- Increase concurrent request limit
- Allocate more memory

## ğŸ§ª Testing

```bash
# Unit tests
go test ./...

# Integration tests
./examples/api_examples.sh

# Load testing
make test-load
```

## ğŸ“ Documentation

| Document | Purpose |
|----------|---------|
| `README.md` | Main documentation and overview |
| `QUICKSTART.md` | Get started in 5 minutes |
| `docs/API.md` | Complete API reference |
| `docs/CONFIGURATION.md` | All configuration options |
| `docs/TESTING.md` | Testing guide |
| `docs/DEPLOYMENT.md` | Production deployment |

## ğŸ”„ Workflow

1. **Client** sends generation request to Go server
2. **Go Server** validates request and creates job
3. **Go Server** forwards to Python backend via HTTP
4. **Python Backend** loads model (if not cached)
5. **Python Backend** generates video using GPU
6. **Python Backend** saves video and returns path
7. **Go Server** updates job status
8. **Client** polls for status and downloads result

## ğŸ¨ Use Cases

- **Content Creation**: Automated video content generation
- **Marketing**: Product visualization and ads
- **Education**: Instructional video creation
- **Entertainment**: Story visualization
- **Prototyping**: Rapid video concept testing
- **Research**: AI/ML experimentation

## ğŸŒŸ Future Enhancements

- [ ] Web UI dashboard
- [ ] Batch processing
- [ ] Video upscaling
- [ ] Frame interpolation
- [ ] Multiple model support
- [ ] Ollama integration
- [ ] Authentication system
- [ ] Cloud storage (S3, GCS)
- [ ] WebSocket streaming
- [ ] Job queue with Redis
- [ ] Kubernetes deployment
- [ ] API rate limiting per user
- [ ] Video editing features
- [ ] Custom model fine-tuning

## ğŸ‘¥ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ License

MIT License - see `LICENSE` file

## ğŸ™ Acknowledgments

- **Lightricks** - LTX-Video model
- **Hugging Face** - Model hosting and Diffusers library
- **LocalAI** - Inspiration for architecture
- **Go Community** - Excellent libraries and tools
- **PyTorch Team** - Deep learning framework

## ğŸ“ Support

- ğŸ“– Documentation: See `docs/` folder
- ğŸ› Bug Reports: GitHub Issues
- ğŸ’¡ Feature Requests: GitHub Issues
- ğŸ“§ Email: support@example.com

---

**Built with â¤ï¸ for the AI video generation community**
