╔══════════════════════════════════════════════════════════════════╗
║              GPU COMPATIBILITY QUICK REFERENCE                   ║
╚══════════════════════════════════════════════════════════════════╝

┌─────────────────────────────────────────────────────────────────┐
│ NVIDIA GPUs (CUDA) - ✅ NATIVE SUPPORT                          │
└─────────────────────────────────────────────────────────────────┘

GPU Model           VRAM    LTX-Video   Status
─────────────────────────────────────────────────────────────────
GTX 1060/1070       6-8GB   ❌          Too small
RTX 2060            6GB     ❌          Too small
RTX 2070/2080       8GB     ⚠️          Extreme limits only
RTX 3060            12GB    ✅          Minimal settings
RTX 3070            8GB     ⚠️          Extreme limits only
RTX 3080            10-12GB ✅          Good
RTX 3090            24GB    ✅✅         Excellent
RTX 4070 Ti         12GB    ✅          Good
RTX 4080            16GB    ✅✅         Excellent
RTX 4090            24GB    ✅✅✅        Perfect
Tesla T4            16GB    ✅✅         Excellent
Tesla V100          16-32GB ✅✅✅        Perfect
A100                40-80GB ✅✅✅        Best

Setup: ./setup.sh (automatic CUDA detection)


┌─────────────────────────────────────────────────────────────────┐
│ AMD GPUs (ROCm) - ⚠️ LINUX ONLY, MANUAL SETUP                  │
└─────────────────────────────────────────────────────────────────┘

GPU Model           VRAM    ROCm        Status
─────────────────────────────────────────────────────────────────
RX 7900 XTX         24GB    ✅ 5.7+     Excellent (RDNA 3)
RX 7900 XT          20GB    ✅ 5.7+     Excellent (RDNA 3)
RX 7800 XT          16GB    ✅ 5.7+     Excellent (RDNA 3)
RX 7700 XT          12GB    ✅ 5.7+     Good (RDNA 3)
RX 6950 XT          16GB    ✅ 5.4+     Excellent (RDNA 2)
RX 6900 XT          16GB    ✅ 5.4+     Excellent (RDNA 2)
RX 6800 XT          16GB    ✅ 5.4+     Excellent (RDNA 2)
RX 6700 XT          12GB    ✅ 5.4+     Good (RDNA 2)
RX 5700 XT          8GB     ⚠️ 5.0+     Limited (RDNA 1)
Vega 64             8GB     ⚠️ 4.5+     Limited (GCN 5)

Setup: ./setup_rocm.sh (Linux only, Ubuntu 20.04/22.04)
Check: python scripts/check_amd_gpu.py

⚠️ Windows: ROCm not officially supported
   Alternative: Use DirectML (experimental) or CPU mode


┌─────────────────────────────────────────────────────────────────┐
│ INTEL GPUs - ⚠️ EXPERIMENTAL                                    │
└─────────────────────────────────────────────────────────────────┘

GPU Model           Support     Notes
─────────────────────────────────────────────────────────────────
Arc A770            ⚠️ Exp      oneAPI/Intel Extension for PyTorch
Arc A750            ⚠️ Exp      Limited support
Iris Xe (Laptop)    ❌          Not recommended

Setup: Requires Intel Extension for PyTorch (ipex)
Status: Not officially supported, CPU mode recommended


┌─────────────────────────────────────────────────────────────────┐
│ APPLE SILICON (M1/M2/M3) - ⚠️ EXPERIMENTAL                      │
└─────────────────────────────────────────────────────────────────┘

Chip                RAM     Support     Notes
─────────────────────────────────────────────────────────────────
M1/M1 Pro          16GB    ⚠️ MPS      Experimental
M1 Max/Ultra       32-64GB ⚠️ MPS      Experimental
M2/M2 Pro          16GB    ⚠️ MPS      Experimental
M2 Max/Ultra       32-96GB ⚠️ MPS      Experimental
M3/M3 Pro/Max      16-128GB⚠️ MPS      Experimental

Setup: Requires PyTorch MPS backend
Status: CPU mode recommended for stability


┌─────────────────────────────────────────────────────────────────┐
│ CPU MODE - ✅ WORKS EVERYWHERE                                  │
└─────────────────────────────────────────────────────────────────┘

Processor           Cores   RAM     Performance
─────────────────────────────────────────────────────────────────
Intel i5/i7         4-8     16GB    Slow (15-30 min/video)
Intel i9            8-16    32GB    Medium (10-20 min/video)
AMD Ryzen 5/7       6-12    16GB    Slow (15-30 min/video)
AMD Ryzen 9         12-16   32GB    Medium (10-20 min/video)
Threadripper        24-64   64GB+   Better (5-15 min/video)
Xeon/EPYC           16-64   64GB+   Better (5-15 min/video)

Setup: Just set ENABLE_GPU=false in .env
Works on: Windows, Linux, macOS, Any CPU


┌─────────────────────────────────────────────────────────────────┐
│ CONFIGURATION GUIDE                                             │
└─────────────────────────────────────────────────────────────────┘

Your Hardware                   Recommended Configuration
─────────────────────────────────────────────────────────────────
NVIDIA GPU (12GB+)              Use default setup ✅
NVIDIA GPU (4-8GB)              CPU mode or cloud GPU
AMD GPU (12GB+, Linux)          Run: ./setup_rocm.sh
AMD GPU (Windows)               CPU mode (ROCm not on Windows)
Intel GPU                       CPU mode
Apple Silicon                   CPU mode
No GPU / Any CPU                CPU mode (works fine!)


┌─────────────────────────────────────────────────────────────────┐
│ QUICK SETUP COMMANDS                                            │
└─────────────────────────────────────────────────────────────────┘

# NVIDIA GPU (automatic)
./setup.sh

# AMD GPU (Linux only)
./setup_rocm.sh

# CPU Mode (any system)
./setup.sh
# Then edit .env:
ENABLE_GPU=false

# Check your GPU
python scripts/check_amd_gpu.py    # AMD
nvidia-smi                          # NVIDIA


┌─────────────────────────────────────────────────────────────────┐
│ PERFORMANCE COMPARISON (256x256, 32 frames)                     │
└─────────────────────────────────────────────────────────────────┘

Hardware                Time        Notes
─────────────────────────────────────────────────────────────────
RTX 4090 (24GB)        ~15s        Best ✅✅✅
RTX 3090 (24GB)        ~25s        Excellent ✅✅
A100 (40GB)            ~20s        Excellent ✅✅
RTX 3080 (12GB)        ~40s        Good ✅
RX 7900 XTX (24GB)     ~30s        Excellent ✅✅ (with ROCm)
RX 6900 XT (16GB)      ~45s        Good ✅ (with ROCm)
Tesla T4 (16GB)        ~50s        Good ✅
RTX 3060 (12GB)        ~60s        Acceptable ✅
CPU (i9-12900K)        ~600s       Slow but works ⚠️
CPU (Ryzen 9 5950X)    ~550s       Slow but works ⚠️


┌─────────────────────────────────────────────────────────────────┐
│ CLOUD GPU OPTIONS (If local GPU insufficient)                  │
└─────────────────────────────────────────────────────────────────┘

Service             GPU         VRAM    Cost        Free Tier
─────────────────────────────────────────────────────────────────
Google Colab        T4          16GB    Free/Paid   ✅ Yes
Kaggle              P100/T4     16GB    Free        ✅ Yes
RunPod              Various     8-80GB  $0.20-2/hr  ❌ No
Vast.ai             Various     8-80GB  $0.15-1/hr  ❌ No
Lambda Labs         A100        40GB    $1.10/hr    ❌ No


═══════════════════════════════════════════════════════════════════

SUMMARY:
  • NVIDIA GPU: ✅ Works out of the box
  • AMD GPU: ⚠️ Linux only, run ./setup_rocm.sh
  • Any CPU: ✅ Always works (slow)
  • Windows + AMD: ❌ Use CPU mode or cloud GPU
  • 4GB GPU: ❌ Not enough, use CPU or cloud

═══════════════════════════════════════════════════════════════════
